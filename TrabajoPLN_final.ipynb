{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3179834a",
   "metadata": {
    "id": "3179834a"
   },
   "source": [
    "# Trabajo PLN : Clasificación Multietiqueta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e434b-f646-46d9-8b88-5f4e57008950",
   "metadata": {},
   "source": [
    "Alumnos: Jorge Albalat, Andreu Cantó, Amparo Gálvez y Mario Herranz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f39241-7b39-408c-95d9-19c4e2928001",
   "metadata": {},
   "source": [
    "## 0. Carga de todas las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124d4019-774c-430c-ba91-1aa72fcfcd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eadd25",
   "metadata": {
    "id": "b5eadd25"
   },
   "source": [
    "## 1. Pre-Procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761fb84-5ea3-4387-942f-1253292a75a5",
   "metadata": {},
   "source": [
    "En primer lugar, cargamos los datos de entrenamiento y prueba. Los datos consisten en tweets etiquetados con múltiples emociones. Utilizamos el conjunto de entrenamiento para entrenar los modelos y el conjunto de prueba para evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8642cf7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8642cf7f",
    "outputId": "1dab82b6-347a-47a3-c3e6-fb4d00518aec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function spacy.pipeline.functions.merge_entities(doc: spacy.tokens.doc.Doc)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el modelo de lenguaje en español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "# Añadir el pipe para merge_entities\n",
    "nlp.add_pipe(\"merge_entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b64da05",
   "metadata": {
    "id": "6b64da05"
   },
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "019fe89a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "019fe89a",
    "outputId": "c5a796db-f5a4-4c72-8c24-46d4b1dc4bb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento:\n",
      "              ID                                              Tweet  anger  \\\n",
      "0  2018-Es-01643  @aliciaenp Ajajjaa somos del clan twitteras pe...  False   \n",
      "1  2018-Es-05142  @AwadaNai la mala suerte del gato fichame la c...  False   \n",
      "2  2018-Es-05379  @audiomano A mí tampoco me agrado mucho eso. E...   True   \n",
      "3  2018-Es-00208  Para llevar a los bebes de un lugar a otro deb...  False   \n",
      "4  2018-Es-01385  @DalasReview me encanta la terrible hipocresia...   True   \n",
      "\n",
      "   anticipation  disgust   fear    joy   love  optimism  pessimism  sadness  \\\n",
      "0         False    False  False   True  False     False      False    False   \n",
      "1         False    False   True  False  False     False       True    False   \n",
      "2         False    False  False  False  False     False      False    False   \n",
      "3         False    False  False   True  False     False      False    False   \n",
      "4         False     True  False  False  False     False      False    False   \n",
      "\n",
      "   surprise  trust  \n",
      "0     False  False  \n",
      "1     False  False  \n",
      "2     False  False  \n",
      "3     False  False  \n",
      "4     False  False  \n"
     ]
    }
   ],
   "source": [
    "# Cargar conjunto de entrenamiento\n",
    "df = pd.read_csv('sem_eval_train_es.csv')\n",
    "\n",
    "# Visualizar las primeras filas para verificar que se hayan cargado correctamente\n",
    "print(\"Conjunto de entrenamiento:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a57d75",
   "metadata": {
    "id": "79a57d75"
   },
   "source": [
    "## 2. Limpieza y normalización de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67952f9-e595-4ff6-900c-be2d9db42a13",
   "metadata": {},
   "source": [
    "Para preparar los datos textuales para su uso en modelos de aprendizaje automático, aplicamos una serie de técnicas de limpieza y normalización, incluyendo la eliminación de caracteres especiales, la conversión a minúsculas y la normalización de las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc47434f",
   "metadata": {
    "id": "fc47434f"
   },
   "outputs": [],
   "source": [
    "# Función para limpiar el texto\n",
    "def clean_text(text):\n",
    "    # Eliminar menciones y URL\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+|https?://[^ ]+', '', text)\n",
    "\n",
    "    # Eliminar el carácter '#' de los hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "\n",
    "    # Eliminar signos de puntuación y palabras menores de 3 caracteres\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b|[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Lematización del texto\n",
    "    doc = nlp(text)\n",
    "    lemmatized_text = ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "    # Eliminar emoticonos y caracteres especiales\n",
    "    lemmatized_text = re.sub(r'[^\\w\\s]', '', lemmatized_text)\n",
    "\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2e1e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Ajajjaa ser del clar twittera perdido   even...\n",
       "1       malo suerte del gato fichame   cara   help ...\n",
       "2        tampoco   agrado mucho ese especialmente p...\n",
       "3    para llevar   el bebes    lugar   otro deber c...\n",
       "4       encanta   terrible hipocresia   doble moral...\n",
       "Name: Clean_Text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Limpiar el texto\n",
    "df['Clean_Text'] = df['Tweet'].apply(clean_text)\n",
    "df['Clean_Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93b7e4",
   "metadata": {
    "id": "2f93b7e4"
   },
   "source": [
    "### Tokenizado de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7540bb37",
   "metadata": {
    "id": "7540bb37"
   },
   "outputs": [],
   "source": [
    "# Función que normaliza un conjunto de tweets limpios\n",
    "def normaliza(texto):\n",
    "    \"\"\"Función que normaliza un string de texto\n",
    "    Entrada: string a normalizar\n",
    "    Devuelve: string del texto normalizado\"\"\"\n",
    "    doc = nlp(texto)\n",
    "    norm = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            lema = token.lemma_\n",
    "            # Si el token es una entidad nombrada, lo reemplazamos con una etiqueta específica\n",
    "            if token.ent_type_ == 'PER':\n",
    "                lema = 'PERSONA'\n",
    "            elif token.ent_type_ == 'LOC':\n",
    "                lema = 'LUGAR'\n",
    "            elif token.ent_type_ == 'ORG':\n",
    "                lema = 'ORGANIZACIÓN'\n",
    "            elif token.ent_type_ == 'MISC':\n",
    "                lema = 'OTRO'\n",
    "\n",
    "            norm.append(lema)\n",
    "\n",
    "    return ' '.join(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b685f7",
   "metadata": {
    "id": "76b685f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       PERSONA clar twittera perdido    evento imp...\n",
       "1        malo suerte gato fichame    cara    helpir...\n",
       "2            agrado especialmente tratar      justi...\n",
       "3       bebes     lugar    deber cantarl canción   ...\n",
       "4        encantar    terrible hipocresia    doble m...\n",
       "Name: Normalized_Text, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizar el texto (opcional)\n",
    "df['Normalized_Text'] = df['Clean_Text'].apply(normaliza)\n",
    "df['Normalized_Text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c783bf67-ee5d-4c94-a8b6-b28925b1ba8a",
   "metadata": {},
   "source": [
    "## 3. Vectorización del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44733d3-6072-4435-a40c-9348f5d6a9b7",
   "metadata": {},
   "source": [
    "Convertimos el texto normalizado en vectores de características utilizando la matriz BoW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e568ef51",
   "metadata": {
    "id": "e568ef51"
   },
   "outputs": [],
   "source": [
    "# Crear la matriz BoW usando Normalized_Text\n",
    "vectorizador = CountVectorizer()\n",
    "X = vectorizador.fit_transform(df['Normalized_Text']).toarray()\n",
    "\n",
    "# Convertir las etiquetas a formato binario\n",
    "y = df[['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']].values\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e62f23a",
   "metadata": {},
   "source": [
    "## 4. Modelado y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a699a-ccc3-4af1-938a-8f356debd1f5",
   "metadata": {},
   "source": [
    "### Red Neuronal Multicapa (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13a9e20-13c3-4975-9241-b97c2ecb8fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/72 [=========================>....] - ETA: 0s - loss: 0.5406 - accuracy: 0.1562\n",
      "Epoch 1: val_loss improved from inf to 0.40788, saving model to best_model_mlp.h5\n",
      "72/72 [==============================] - 1s 9ms/step - loss: 0.5238 - accuracy: 0.1874 - val_loss: 0.4079 - val_accuracy: 0.3509\n",
      "Epoch 2/50\n",
      "17/72 [======>.......................] - ETA: 0s - loss: 0.3816 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/72 [============================>.] - ETA: 0s - loss: 0.3743 - accuracy: 0.4912\n",
      "Epoch 2: val_loss improved from 0.40788 to 0.38713, saving model to best_model_mlp.h5\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.3745 - accuracy: 0.4917 - val_loss: 0.3871 - val_accuracy: 0.4316\n",
      "Epoch 3/50\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.3152 - accuracy: 0.5529\n",
      "Epoch 3: val_loss improved from 0.38713 to 0.36663, saving model to best_model_mlp.h5\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.3131 - accuracy: 0.5562 - val_loss: 0.3666 - val_accuracy: 0.4333\n",
      "Epoch 4/50\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.2309 - accuracy: 0.6614\n",
      "Epoch 4: val_loss improved from 0.36663 to 0.35739, saving model to best_model_mlp.h5\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.2301 - accuracy: 0.6615 - val_loss: 0.3574 - val_accuracy: 0.4632\n",
      "Epoch 5/50\n",
      "68/72 [===========================>..] - ETA: 0s - loss: 0.1602 - accuracy: 0.7123\n",
      "Epoch 5: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.1602 - accuracy: 0.7133 - val_loss: 0.3827 - val_accuracy: 0.4246\n",
      "Epoch 6/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.7287\n",
      "Epoch 6: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 7ms/step - loss: 0.1119 - accuracy: 0.7287 - val_loss: 0.4136 - val_accuracy: 0.4175\n",
      "Epoch 7/50\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.0800 - accuracy: 0.7262\n",
      "Epoch 7: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.7305 - val_loss: 0.4420 - val_accuracy: 0.4298\n",
      "Epoch 8/50\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.0605 - accuracy: 0.7264\n",
      "Epoch 8: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.7261 - val_loss: 0.4807 - val_accuracy: 0.4158\n",
      "Epoch 9/50\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.0466 - accuracy: 0.7228\n",
      "Epoch 9: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0478 - accuracy: 0.7226 - val_loss: 0.5043 - val_accuracy: 0.4018\n",
      "Epoch 10/50\n",
      "67/72 [==========================>...] - ETA: 0s - loss: 0.0396 - accuracy: 0.7215\n",
      "Epoch 10: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.7169 - val_loss: 0.5382 - val_accuracy: 0.3684\n",
      "Epoch 11/50\n",
      "65/72 [==========================>...] - ETA: 0s - loss: 0.0331 - accuracy: 0.7216\n",
      "Epoch 11: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0334 - accuracy: 0.7217 - val_loss: 0.5745 - val_accuracy: 0.3526\n",
      "Epoch 12/50\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.0281 - accuracy: 0.7093\n",
      "Epoch 12: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0288 - accuracy: 0.7063 - val_loss: 0.5926 - val_accuracy: 0.3632\n",
      "Epoch 13/50\n",
      "69/72 [===========================>..] - ETA: 0s - loss: 0.0256 - accuracy: 0.7047\n",
      "Epoch 13: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0254 - accuracy: 0.7046 - val_loss: 0.6265 - val_accuracy: 0.3404\n",
      "Epoch 14/50\n",
      "66/72 [==========================>...] - ETA: 0s - loss: 0.0237 - accuracy: 0.7188\n",
      "Epoch 14: val_loss did not improve from 0.35739\n",
      "72/72 [==============================] - 0s 6ms/step - loss: 0.0231 - accuracy: 0.7191 - val_loss: 0.6488 - val_accuracy: 0.3439\n"
     ]
    }
   ],
   "source": [
    "# Definición del modelo secuencial\n",
    "model_mlp = Sequential()\n",
    "\n",
    "# Capa densa con 128 unidades y activación ReLU, con entrada del tamaño de X_train\n",
    "model_mlp.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "\n",
    "# Capa densa con 64 unidades y activación ReLU\n",
    "model_mlp.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Capa de salida con 11 unidades (correspondientes a 11 etiquetas) y activación sigmoide para salida binaria\n",
    "model_mlp.add(Dense(11, activation='sigmoid'))\n",
    "\n",
    "# Compilación del modelo con optimizador Adam y pérdida de entropía cruzada binaria\n",
    "model_mlp.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Definición de callbacks: guardado del mejor modelo y parada temprana\n",
    "checkpoint = ModelCheckpoint('best_model_mlp.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Entrenamiento del modelo con validación del 20% de los datos, durante 50 épocas y con tamaño de lote de 32\n",
    "history_mlp = model_mlp.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d326f9-3955-4911-a46c-ce2f070771e4",
   "metadata": {},
   "source": [
    "### Regresión Logística Multietiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a26350fa-d8cd-4e36-accf-b5c169cf5397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ampar\\Anaconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression params: {'estimator__C': 10, 'estimator__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "# Parámetros de búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'estimator__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'estimator__solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "# Definir el modelo de regresión logística multietiqueta\n",
    "model_lr = MultiOutputClassifier(LogisticRegression())\n",
    "\n",
    "# Configuración de búsqueda en cuadrícula\n",
    "grid_search_lr = GridSearchCV(model_lr, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# Ajustar el modelo\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Extraer los mejores parámetros\n",
    "best_params = grid_search_lr.best_params_\n",
    "print(f\"Best Logistic Regression params: {best_params}\")\n",
    "\n",
    "# Crear un nuevo modelo LogisticRegression con los mejores parámetros\n",
    "best_estimator_params = {\n",
    "    'C': best_params['estimator__C'],\n",
    "    'solver': best_params['estimator__solver']\n",
    "}\n",
    "best_lr_model = LogisticRegression(**best_estimator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4508f4-db0e-438b-af56-709616d967da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifier(estimator=LogisticRegression(C=10, solver=&#x27;liblinear&#x27;))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputClassifier</label><div class=\"sk-toggleable__content\"><pre>MultiOutputClassifier(estimator=LogisticRegression(C=10, solver=&#x27;liblinear&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;liblinear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(C=10, solver='liblinear'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear el MultiOutputClassifier con el mejor modelo LogisticRegression\n",
    "best_lr = MultiOutputClassifier(best_lr_model)\n",
    "\n",
    "# Entrenar el modelo con los mejores parámetros\n",
    "best_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f611d5a-4e10-44bc-9692-a663eb6b5cd2",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cbedf84-9323-49d0-b322-73dd05bb1541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest params: {'bootstrap': False, 'max_depth': 86, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 110}\n"
     ]
    }
   ],
   "source": [
    "# Definición de la distribución de parámetros para la búsqueda aleatoria\n",
    "param_dist = {\n",
    "    'n_estimators': randint(10, 200),\n",
    "    'max_depth': randint(1, 100),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Definición del modelo Random Forest\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Configuración de la búsqueda aleatoria con 50 iteraciones y 3 folds de validación cruzada\n",
    "random_search_rf = RandomizedSearchCV(rf, param_dist, n_iter=50, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Ajuste del modelo utilizando la búsqueda aleatoria\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Extracción del mejor estimador (modelo) y sus parámetros óptimos\n",
    "best_rf = random_search_rf.best_estimator_\n",
    "print(f\"Best Random Forest params: {random_search_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4f0baf5-092d-4ea6-b33e-d79406a1dba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=False, max_depth=86, min_samples_leaf=3,\n",
       "                       n_estimators=110, n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(bootstrap=False, max_depth=86, min_samples_leaf=3,\n",
       "                       n_estimators=110, n_jobs=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=86, min_samples_leaf=3,\n",
       "                       n_estimators=110, n_jobs=-1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=False,n_estimators=110, max_depth=86, min_samples_leaf=3, min_samples_split=2)\n",
    "# Entrenamiento del modelo con los mejores parámetros\n",
    "best_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2301bb3b-9d5c-4048-aa65-be9231a9261f",
   "metadata": {},
   "source": [
    "## 5. Evaluación de los Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b311bc23-71d3-4eea-afc7-363b8f72eaea",
   "metadata": {},
   "source": [
    "Evaluamos los modelos utilizando el conjunto de validación y comparamos sus métricas de rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2436e4-9e80-4f79-a336-8fc9e050843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.4502\n"
     ]
    }
   ],
   "source": [
    "# Cargar y evaluar el modelo MLP\n",
    "model_mlp.load_weights('best_model_mlp.h5')\n",
    "loss_mlp, accuracy_mlp = model_mlp.evaluate(X_val, y_val)\n",
    "\n",
    "# Cargar y evaluar el modelo Random Forest\n",
    "loss_rf, accuracy_rf = best_rf.score(X_val, y_val), accuracy_score(y_val, best_rf.predict(X_val))\n",
    "\n",
    "# Cargar y evaluar el modelo Regresion Logistica\n",
    "loss_lr, accuracy_lr = best_lr.score(X_val, y_val), accuracy_score(y_val, best_lr.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3535528-e5c7-4610-b2af-fcf884100be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: MLP\n",
      "  Pérdida en validación: 0.3552181124687195\n",
      "  Precisión en validación: 0.4502103924751282\n",
      "Modelo: Logistic Regression\n",
      "  Pérdida en validación: 0.19074333800841514\n",
      "  Precisión en validación: 0.19074333800841514\n",
      "Modelo: Random Forest\n",
      "  Pérdida en validación: 0.15287517531556802\n",
      "  Precisión en validación: 0.15287517531556802\n"
     ]
    }
   ],
   "source": [
    "# Almacenar los resultados en una lista\n",
    "results = [\n",
    "    {'model': 'MLP', 'loss': loss_mlp, 'accuracy': accuracy_mlp},\n",
    "    {'model': 'Logistic Regression', 'loss': loss_lr, 'accuracy': accuracy_lr},\n",
    "    {'model': 'Random Forest', 'loss': loss_rf, 'accuracy': accuracy_rf}\n",
    "]\n",
    "\n",
    "# Mostrar todos los resultados a la vez\n",
    "for result in results:\n",
    "    print(f\"Modelo: {result['model']}\")\n",
    "    print(f\"  Pérdida en validación: {result['loss']}\")\n",
    "    print(f\"  Precisión en validación: {result['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1956fc",
   "metadata": {},
   "source": [
    "## 6. Predicción en el Conjunto de Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c1f18-2b0b-471f-9577-dfc7c9669352",
   "metadata": {},
   "source": [
    "Realizamos predicciones con el modelo MLP en el conjunto de prueba y guardamos los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lyrsV2l3uXBs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyrsV2l3uXBs",
    "outputId": "b985ef88-0201-4452-93fc-bfefe286a6e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predecir en el conjunto de test\n",
    "df_test = pd.read_csv('sem_eval_test_grupo_12.csv')\n",
    "df_test['Clean_Text'] = df_test['Tweet'].apply(clean_text)\n",
    "df_test['Normalized_Text'] = df_test['Clean_Text'].apply(normaliza)\n",
    "X_test = vectorizador.transform(df_test['Normalized_Text']).toarray()\n",
    "predicciones = model_mlp.predict(X_test)\n",
    "predicciones_binarias = (predicciones > 0.5).astype(int)\n",
    "\n",
    "soluciones_df = pd.DataFrame(predicciones_binarias, columns=['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust'])\n",
    "soluciones_df.insert(0, 'ID', df_test['ID'])\n",
    "soluciones_df.to_csv('soluciones_grupo_12.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9feddc6-acbb-4117-834a-e5e62859acaa",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b202166-b2fa-4a9b-8483-e8663a912690",
   "metadata": {},
   "source": [
    "En este trabajo, hemos desarrollado y evaluado diferentes modelos de clasificación multietiqueta para la detección de emociones en tweets en español. Utilizamos una red neuronal multicapa (MLP), regresión logística y un random forest, optimizando los hiperparámetros de cada modelo y comparando su rendimiento en términos de pérdida y precisión en el conjunto de validación.\n",
    "\n",
    "La red neuronal multicapa (MLP) mostró una precisión superior en la clasificación de emociones en comparación con la regresión logística y el random forest, a pesar de tener una mayor pérdida. Esto sugiere que la MLP tiene una mejor capacidad para capturar las complejidades de los datos multietiqueta, aunque podría beneficiarse de una mayor optimización para reducir la pérdida.\n",
    "\n",
    "Por otro lado, la regresión logística y el random forest presentaron una pérdida menor, pero su precisión fue inferior, lo que indica que aunque estos modelos son buenos para minimizar la función de pérdida, tienen dificultades para predecir correctamente las etiquetas emocionales en comparación con la MLP.\n",
    "\n",
    "En conclusión, la MLP demostró ser el modelo más efectivo para la tarea de clasificación multietiqueta de emociones en tweets en español."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
